ğŸŒŠ Amazon River RAG Application

Document Search & Summarization using FAISS + Ollama + Streamlit

ğŸ“Œ Project Overview

This project is a Retrieval-Augmented Generation (RAG) application that allows users to ask questions about the Amazon River using a PDF document as the knowledge source.

The system:

Retrieves relevant document sections using FAISS vector search

Generates accurate answers using a local LLM powered by Ollama

Provides a clean and interactive Streamlit UI

âš¡ Fully offline | No API limits | No cloud dependency

ğŸ§  Architecture
PDF Document
     â†“
Text Chunking
     â†“
Sentence Embeddings
     â†“
FAISS Vector Index
     â†“
User Question
     â†“
Semantic Search (FAISS)
     â†“
Retrieved Context
     â†“
Ollama LLM (llama3)
     â†“
Final Answer (Streamlit UI)

ğŸ› ï¸ Tech Stack
Component	Technology
Frontend	Streamlit
Vector Search	FAISS
Embeddings	Sentence Transformers (all-MiniLM-L6-v2)
LLM	Ollama (llama3)
Language	Python
ğŸ“ Project Structure
GenAI_Project/
â”‚
â”œâ”€â”€ ingest.py              # PDF ingestion + FAISS index creation
â”œâ”€â”€ app.py                 # Streamlit RAG application
â”œâ”€â”€ Amazon_River.pdf       # Input document
â”œâ”€â”€ amazon_index.faiss     # FAISS vector index
â”œâ”€â”€ chunks.pkl             # Stored document chunks
â””â”€â”€ README.md

âš™ï¸ Setup Instructions
1ï¸âƒ£ Create Virtual Environment
python -m venv .venv
source .venv/Scripts/activate   # Windows

2ï¸âƒ£ Install Dependencies
pip install streamlit faiss-cpu sentence-transformers pypdf

ğŸ§  Install Ollama (Local LLM)
Download Ollama

ğŸ‘‰ https://ollama.com/download

Pull Model
ollama pull llama3

Verify
ollama run llama3

ğŸ“¥ Step 1: Build FAISS Index

Run the ingestion script to process the PDF:

python ingest.py


This will generate:

amazon_index.faiss

chunks.pkl

ğŸš€ Step 2: Run the Application
streamlit run app.py


Open browser at:

http://localhost:8501
